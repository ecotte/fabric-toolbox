{
  "queryset": {
    "version": "1.0.0",
    "dataSources": [
      {
        "id": "73fd416c-9a7c-4bce-8930-a3c3e01e67ee",
        "clusterUri": "",
        "type": "Fabric",
        "databaseItemId": "8323dfe0-6c03-a3ce-4a50-dc0604cff8ed",
        "databaseItemName": "SparkMonitoring"
      }
    ],
    "tabs": [
      {
        "id": "535e97e3-310a-4dad-bd9e-213b61aad0a6",
        "content": "\nsparklens_metrics\n| where app_id ==\"application_1747977746836_0001\"\n\n\ningestionTable | summarize max(timestamp),min(timestamp) by applicationId | where applicationId != \"\"\n\ningestionTable \n| extend props = parse_json(properties)\n| where applicationId == \"application_1747982702156_0001\" \n|  where props.name contains \"JVMCPU.jvmcpuTime\" \n| summarize max(tolong(props.value)) by bin(timestamp,1m) , name_ = tostring(props.name) \n| sort by name_ asc, timestamp asc\n| extend Rank = row_number(1, prev(name_) != name_)\n| extend nanosecondsSoFar = Rank * 60000000000\n| extend utilization = todouble(max_props_value / nanosecondsSoFar)\n| project utilization, max_props_value, nanosecondsSoFar, name_, timestamp, Rank\n\ningestionTable \n| extend props = parse_json(properties) \n| where applicationId == 'application_1747982702156_0001'\n|  where props.name contains 'jvm.heap.used' or props.name contains \"jvm.heap.max\" \n| summarize avg(tolong(props.value)) by bin(timestamp,1m),tostring(props.name)\n\ningestionTable\n| where applicationId == 'application_1747982702156_0001'\n| extend props = parse_json(properties) \n| where properties contains \"applicationMaster.numExecutorsFailed\"\n| summarize max(tolong(props.value))\n\ningestionTable\n| where applicationId == 'application_1747982702156_0001'\n| extend props = parse_json(properties) \n| where  properties contains \"SparkListenerTaskEnd\"\n| project  rsn=props\n| summarize count_distinct(tostring(rsn))\n\n\ningestionTable\n| where properties contains \"datasource\" and properties contains \"is_success\"\n| extend datasource=extract(@\"datasource:\\s+([^|]+)\", 1, properties)\n| extend run_time = extract(@\"run_time:\\s([^\\|]+)\", 1, properties)\n| extend is_success = extract(@\"is_success:\\s(\\w+)\", 1, properties)\n| extend expectation_type = extract(@\"expectation_type:\\s([^\\|]+)\", 1, properties)\n| extend element_count = toint(extract(@\"element_count:\\s(\\d+)\", 1, properties))\n| extend unexpected_count = toint(extract(@\"unexpected_count:\\s(\\d+)\", 1, properties))\n| project applicationId,run_time, datasource, is_success, expectation_type, element_count, unexpected_count\n| project properties\n\n\ningestionTable\n| where properties contains \"Source Table \"\n|  extend tableNames = extract(@\"Source Table '([^']+)'\", 1, properties)\n| summarize by  tableNames\n| limit 100\n\n\ningestionTable\n| where category ==\"EventLog\"\n| limit 100\n\n| distinct category\n\ningestionTable\n| where properties contains \"fact_sales\"\n| where properties contains \"Total Time (End-to-End Duration) for Loading Data from\" or properties contains \"Size of Source DataFrame\" or properties contains \"Row Count in Source Table\"\n| extend duration = extract(@\"(\\d+\\.\\d+) seconds\", 1, properties)\n| extend rowCount = extract(@\"Row Count in Source Table '([^']+)': (\\d+)\", 2, properties)\n| extend sizeMBs = extract(@\"Size of Source DataFrame .*?: (\\d+\\.\\d+) MB\", 1, properties)\n| extend Operation = extract(\"Workload - ([^-]+) - Application ID\", 1, properties)\n| project timestamp, todecimal(duration), toint(rowCount), todecimal(sizeMBs),tostring(Operation), properties, applicationId\n| summarize \n    max(\"\"),\n    sum(duration),\n    sum(rowCount),\n    sum(sizeMBs)\n    by bin(timestamp, 1m), applicationId,Operation\n| where Operation != \"\"\n\n\n\ningestionTable\n| where properties contains \"MERGE\"\n| where properties contains \"// tableName - dim_customers //\"\n| distinct properties\n| extend timestamp = extract(@\"timestamp (\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})\", 1, properties)\n| extend tableName = extract(@\"tableName - ([^ ]+)\", 1, properties)\n| extend numTargetRowsCopied = extract(@\"'numTargetRowsCopied': '(\\d+)'\" , 1, properties)\n| extend numTargetRowsUpdated = extract(@\"'numTargetRowsUpdated': '(\\d+)'\" , 1, properties)\n| extend numTargetRowsInserted = extract(@\"'numTargetRowsInserted': '(\\d+)'\" , 1, properties)\n| extend numOutputRows = extract(@\"'numOutputRows': '(\\d+)'\" , 1, properties)\n| project timestamp, tableName, tolong(numTargetRowsCopied), tolong(numTargetRowsUpdated), tolong(numTargetRowsInserted), tolong(numOutputRows)\n| summarize sum(numTargetRowsCopied),sum(numTargetRowsUpdated),sum(numTargetRowsInserted),sum(numOutputRows) by tableName, bin(todatetime(timestamp),1m)\n\n\ningestionTable\n| extend props = parse_json(properties) \n//| where applicationId ==\"application_1747982702156_0001\"\n| where properties contains \"shuffleWriteTime\" or properties contains \"shuffleFetchWaitTime\"\n| project timestamp,cnt_=tolong(props.count),props.name\n| where cnt_!=0\n| limit 100\n\n\n\ningestionTable\n| where timestamp >= ago(30d)\n| where properties contains \"table size:\"\n| extend tableSize = extract(@\"table size:\\s*(\\d+)\", 1, properties)\n| extend tableName = extract(@\"Tables/([^|]+)\", 1, properties)\n| project timestamp, tableName, tableSize = tolong(tableSize)\n| sort by tableName,timestamp desc\n| extend Rank=row_number(1, prev(tableName) != tableName)\n| where Rank ==1\n\n\ningestionTable\n| where properties contains \"// tableName - dim_customers\" //\"\n| distinct properties\n| extend timestamp = extract(@\"timestamp (\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})\", 1, properties)\n| extend tableName = extract(@\"tableName - ([^ ]+)\", 1, properties)\n| extend numOutputRows = extract(@\"'numOutputRows': '(\\d+)'\" , 1, properties)\n| extend operationType = extract(\"operation - ([^ ]+)\", 1, properties)\n| project timestamp, tableName, tolong(numOutputRows),operationType\n| summarize sum(numOutputRows) by tableName, bin(todatetime(timestamp),1m),operationType\n\ningestionTable \n| where properties contains \"numGlutenNodes\"\n|limit 10\n\n >0\n| project applicationId_s,numGlutenNodes_d, numFallbackNodes_d, physicalPlanDescription_s\n\n\n| order by timestamp desc \n\n| render timechart\n\n\ningestionTable\n| where applicationId contains \"application_1749073295482_0001\"\n| extend props = parse_json(properties)\n| where properties contains \"gluten\" or properties contains \"velox\"\n| project  applicationId,props.numGlutenNodes, props.numFallbackNodes, props.physicalPlanDescription\n\n| limit 10\n\n| limit 100\n\ningestionTable \n        | extend props = parse_json(properties)\n        | where applicationId == 'application_1747974143425_0001' \n        |  where props.name contains 'JVMCPU.jvmcpuTime' \n        | summarize max(tolong(props.value)) by bin(timestamp,1m) , name_ = tostring(props.name) \n        | sort by name_ asc, timestamp asc\n        | extend Rank = row_number(1, prev(name_) != name_)\n        | extend nanosecondsSoFar = Rank * 60000000000\n        | extend utilization = round(toreal(max_props_value) / toreal(nanosecondsSoFar), 5)\n        | project utilization, max_props_value, nanosecondsSoFar, name_, timestamp, Rank\n\n\n\n\ningestionTable\n| where applicationId == \"application_1747974143425_0001\"\n| extend props = parse_json(properties) \n| where  properties contains 'SparkListenerTaskEnd'\n| project stageId=props[\"Stage ID\"], props[\"Task Info\"][\"Partition ID\"], accum= props[\"Task Info\"][\"Accumulables\"],applicationId\n| mv-expand accum\n| extend AccumParsed = parse_json(accum) \n| project tostring(stageId),accumName=tostring(AccumParsed[\"Name\"]), val=tolong(AccumParsed[\"Value\"])\n| summarize min(val),percentile(val,25),percentile(val,50),percentile(val,75),max(val) by stageId,accumName                                                                                                          \n\n\n\nsparklens_recommedations\n| limit 100\n\ningestionTable\n| summarize distinct_count = dcount(applicationId)\n\ningestionTable\n| where timestamp >= ago(2d)\n| summarize count()\n\ningestionTable\n| where timestamp >= datetime(\"2025-06-06 18:00:00.0000\") and timestamp <= datetime(\"2025-06-06 19:00:00.0000\")\n| extend props=parse_json(properties),Packed=pack_all()\n| summarize max(timestamp),min(timestamp),count(),dcappid=dcount(applicationId),pcdlen=sum(strlen(Packed)) by bints=bin(timestamp,10s)\n| join kind=inner (\ningestionTable\n| where timestamp >= datetime(\"2025-06-06 18:00:00.0000\") and timestamp <= datetime(\"2025-06-06 19:00:00.0000\")\n| extend props=parse_json(properties)\n| where properties contains \"jvm.heap.used\"\n| summarize dcount(tostring(props.name)) by bints=bin(timestamp,10s) ) on bints\n| project  bints,dcount_props_name,dcappid,pcdlen,cntPerExecPer10S=count_/dcount_props_name,pcdlengthPerExecPer10S=pcdlen/dcount_props_name\n\n\ningestionTable\n| where \n| extend props=parse_json(properties)\n| summarize max(timestamp),min(timestamp),count(),dcappid=dcount(applicationId) by bints=bin(timestamp,1h)\n| render timechart\n\n\ningestionTable\n| where timestamp >= datetime(\"2025-05-23 02:00:00.0000\") and timestamp <= datetime(\"2025-05-23 03:00:00.0000\")\n| extend props=parse_json(properties),Packed=pack_all()\n| summarize max(timestamp),min(timestamp),count(),dcappid=dcount(applicationId),pcdlen=sum(strlen(Packed)) by bints=bin(timestamp,10s)\n| join kind=inner (\ningestionTable\n| where timestamp >= datetime(\"2025-05-23 02:00:00.0000\") and timestamp <= datetime(\"2025-05-23 03:00:00.0000\")\n| extend props=parse_json(properties)\n| where properties contains \"jvm.heap.used\"\n| summarize dcount(tostring(props.name)) by bints=bin(timestamp,10s) ) on bints\n| project  bints,dcount_props_name,dcappid,pcdlen,cntPerExecPer10S=count_/dcount_props_name,pcdlengthPerExecPer10S=pcdlen/dcount_props_name\n\n\ningestionTable\n| summarize dcount( applicationId)\n\nsparklens_recommedations\n| summarize dcount( app_id)\n\n\ningestionTable\n| where  properties contains \"Running Spark Version\"  and applicationId contains \"application_1747982702156_0001\"\n| project applicationId, properties\n\n\ningestionTable \n| extend props = parse_json(properties) \n| where applicationId == 'application_1747953449033_0001'\n|  where (props.name contains 'jvm.heap.used' or props.name contains 'jvm.heap.max' ) and props.name contains \"driver\"\n| summarize sumif(todouble(props.value),props.name contains 'jvm.heap.used')/sumif(todouble(props.value),props.name contains 'jvm.heap.max') by bin(timestamp,1m),applicationId\n\n\n\ningestionTable\n| where applicationId  in (\"application_1747954335201_0001\")\n| where  properties contains 'SparkListenerTaskEnd'\n| extend props = parse_json(properties)\n| project timestamp,applicationId,stageID=props.[\"Stage ID\"], taskId=props.[\"Task Info\"].[\"Task ID\"],accumulables=props.[\"Task Info\"].[\"Accumulables\"]\n| mv-expand kind=array accumulables \n| project timestamp,applicationId,stageID,taskId, key = accumulables[\"Name\"], val=accumulables[\"Value\"]\n| where key contains \"deserializecputime\"\n\n| extend AllColumns = pack_all()\n| mv-expand kind=array AllColumns \n| extend key = AllColumns[0], val=AllColumns[1]\n| where key startswith \"\"Task_Metrics\"\"\n| project Stage_ID_d, Task_Info_Task_ID_d,Task_Info_Executor_ID_s, Task_Info_Attempt_d, tostring(key), toint(val),applicationId_s\n//| where key startswith \"\"Task_Metrics_Shuffle_Write_Metrics_Shuffle_Write_Time_d\"\"\n| summarize sum(val) by applicationId_s,key,Stage_ID_d\n| summarize min(sum_val),percentile(sum_val,25),percentile(sum_val,50),percentile(sum_val,75),max(sum_val) by applicationId_s,key\n\n\n\ningestionTable \n| extend props = parse_json(properties) \n| where applicationId == \"application_1747954335201_0001\"\n|  where (props.name contains 'jvm.heap.used' or props.name contains 'jvm.heap.max' ) and props.name !contains \"driver\"\n| extend extracted = extract(@\"(application_\\d+_\\d+\\.\\d+\\.jvm\\.heap)\", 1, tostring(props.name))\n| summarize sumif(todouble(props.value),props.name contains 'jvm.heap.used')/sumif(todouble(props.value),props.name contains 'jvm.heap.max') by bin(timestamp,5m),applicationId,tostring(extracted)",
        "title": "Tab",
        "dataSourceId": "73fd416c-9a7c-4bce-8930-a3c3e01e67ee"
      },
      {
        "id": "5c7dc218-7551-43b7-b332-8023472bc289",
        "content": "// Use 'take' to view a sample number of records in the table and check the data.\nsparklens_recommedations\n| take 100\n",
        "title": "",
        "dataSourceId": "73fd416c-9a7c-4bce-8930-a3c3e01e67ee"
      }
    ]
  }
}